#!/usr/bin/env python3
"""
verify_grok_backup.py

S3ä¸Šã®Grok trendingéŠ˜æŸ„ã®ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ãƒ•ã‚¡ã‚¤ãƒ«ã®å­˜åœ¨ã‚’ç¢ºèª

Exit codes:
  0: ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ãŒæ­£å¸¸ã«å­˜åœ¨ã™ã‚‹
  1: ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ãŒä¸å®Œå…¨ã¾ãŸã¯å­˜åœ¨ã—ãªã„
"""

import argparse
import sys
import os
from datetime import datetime
from io import BytesIO

import boto3
from botocore.exceptions import ClientError
import pandas as pd


def verify_s3_backup(bucket: str, date: str) -> bool:
    """
    S3ä¸Šã®ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ãƒ•ã‚¡ã‚¤ãƒ«ã®å­˜åœ¨ã‚’ç¢ºèª

    Args:
        bucket: S3ãƒã‚±ãƒƒãƒˆå
        date: YYYYMMDDå½¢å¼ã®æ—¥ä»˜

    Returns:
        bool: ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ãŒå­˜åœ¨ã™ã‚Œã°True
    """
    s3_client = boto3.client('s3')

    print(f"ğŸ” Verifying S3 backups for date: {date}")
    print(f"ğŸ“¦ Bucket: {bucket}")

    # 1. YYYYMMDD.parquet ã®ç¢ºèª
    key_daily = f"parquet/backtest/grok_trending_{date}.parquet"
    try:
        response = s3_client.head_object(Bucket=bucket, Key=key_daily)
        size = response['ContentLength']
        last_modified = response['LastModified']
        print(f"âœ… S3 daily backup exists: s3://{bucket}/{key_daily}")
        print(f"   Size: {size:,} bytes, Last modified: {last_modified}")
    except ClientError as e:
        if e.response['Error']['Code'] == '404':
            print(f"âŒ S3 daily backup NOT found: s3://{bucket}/{key_daily}")
            return False
        else:
            print(f"âŒ Error checking daily backup: {e}")
            raise

    # 2. archive.parquet ã®ç¢ºèª
    key_archive = "parquet/backtest/grok_trending_archive.parquet"
    try:
        response = s3_client.head_object(Bucket=bucket, Key=key_archive)
        size = response['ContentLength']
        last_modified = response['LastModified']
        print(f"âœ… S3 archive exists: s3://{bucket}/{key_archive}")
        print(f"   Size: {size:,} bytes, Last modified: {last_modified}")

        # ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ã¦è©²å½“æ—¥ã®ãƒ‡ãƒ¼ã‚¿ã‚’ç¢ºèª
        print(f"   Downloading archive to verify date: {date}")
        obj_response = s3_client.get_object(Bucket=bucket, Key=key_archive)
        df_archive = pd.read_parquet(BytesIO(obj_response['Body'].read()))

        if df_archive.empty:
            print(f"âš ï¸ Archive is empty")
            return False

        # è©²å½“æ—¥ã®ãƒ‡ãƒ¼ã‚¿ãŒå­˜åœ¨ã™ã‚‹ã‹ç¢ºèª
        target_date = f"{date[:4]}-{date[4:6]}-{date[6:]}"

        if 'backtest_date' not in df_archive.columns:
            print(f"âŒ Archive does not have 'backtest_date' column")
            return False

        # backtest_date ãŒ datetime.date ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã®å ´åˆã‚‚ã‚ã‚‹ãŸã‚ã€æ–‡å­—åˆ—ã«å¤‰æ›
        df_archive['backtest_date_str'] = df_archive['backtest_date'].astype(str)
        df_day = df_archive[df_archive['backtest_date_str'] == target_date]

        if len(df_day) > 0:
            print(f"âœ… Archive contains data for {target_date}: {len(df_day)} records")

            # è©³ç´°æƒ…å ±ã‚’è¡¨ç¤º
            if 'code' in df_day.columns:
                codes = df_day['code'].unique()
                print(f"   Codes: {', '.join(str(c) for c in codes[:10])}")
                if len(codes) > 10:
                    print(f"   ... and {len(codes) - 10} more")

            return True
        else:
            print(f"âŒ Archive does NOT contain data for {target_date}")
            print(f"   Available dates in archive: {df_archive['backtest_date'].unique()[:10]}")
            return False

    except ClientError as e:
        if e.response['Error']['Code'] == '404':
            print(f"âŒ S3 archive NOT found: s3://{bucket}/{key_archive}")
            return False
        else:
            print(f"âŒ Error checking archive: {e}")
            raise
    except Exception as e:
        print(f"âŒ Error processing archive: {e}")
        raise


def get_target_date_from_parquet(parquet_path: str) -> str | None:
    """
    grok_trending.parquet ã‹ã‚‰å¯¾è±¡æ—¥ä»˜ã‚’å–å¾—

    Args:
        parquet_path: grok_trending.parquet ã®ãƒ‘ã‚¹

    Returns:
        YYYYMMDDå½¢å¼ã®æ—¥ä»˜ã€å–å¾—ã§ããªã„å ´åˆã¯None
    """
    try:
        if not os.path.exists(parquet_path):
            print(f"âš ï¸ Local file not found: {parquet_path}")
            return None

        df = pd.read_parquet(parquet_path)

        if df.empty:
            print(f"âš ï¸ grok_trending.parquet is empty")
            return None

        if 'date' not in df.columns:
            print(f"âŒ grok_trending.parquet does not have 'date' column")
            return None

        # æœ€åˆã®è¡Œã®æ—¥ä»˜ã‚’å–å¾—ï¼ˆå…¨è¡ŒåŒã˜æ—¥ä»˜ã®ã¯ãšï¼‰
        date_str = df['date'].iloc[0]

        # YYYY-MM-DD -> YYYYMMDD
        date_yyyymmdd = date_str.replace('-', '')

        return date_yyyymmdd

    except Exception as e:
        print(f"âŒ Error reading grok_trending.parquet: {e}")
        return None


def main():
    parser = argparse.ArgumentParser(
        description="S3ä¸Šã®Grok trendingéŠ˜æŸ„ã®ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‚’ç¢ºèª"
    )
    parser.add_argument(
        '--bucket',
        required=True,
        help='S3ãƒã‚±ãƒƒãƒˆå'
    )
    parser.add_argument(
        '--date',
        help='ç¢ºèªã™ã‚‹æ—¥ä»˜ï¼ˆYYYYMMDDå½¢å¼ï¼‰ã€‚æŒ‡å®šã—ãªã„å ´åˆã¯grok_trending.parquetã‹ã‚‰å–å¾—'
    )
    parser.add_argument(
        '--parquet-path',
        default='data/parquet/grok_trending.parquet',
        help='grok_trending.parquetã®ãƒ‘ã‚¹ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: data/parquet/grok_trending.parquetï¼‰'
    )

    args = parser.parse_args()

    # æ—¥ä»˜ã®å–å¾—
    if args.date:
        target_date = args.date
        print(f"ğŸ“… Using specified date: {target_date}")
    else:
        print(f"ğŸ“… Reading date from: {args.parquet_path}")
        target_date = get_target_date_from_parquet(args.parquet_path)

        if not target_date:
            print("âŒ Could not determine target date")
            sys.exit(1)

        print(f"ğŸ“… Detected date: {target_date}")

    # æ—¥ä»˜ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã®æ¤œè¨¼
    try:
        datetime.strptime(target_date, '%Y%m%d')
    except ValueError:
        print(f"âŒ Invalid date format: {target_date} (expected YYYYMMDD)")
        sys.exit(1)

    # S3ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã®ç¢ºèª
    try:
        backup_ok = verify_s3_backup(args.bucket, target_date)

        if backup_ok:
            print("\nâœ… All backups verified successfully")
            sys.exit(0)
        else:
            print("\nâŒ Backup verification failed")
            print("âš ï¸ Aborting to prevent data loss")
            sys.exit(1)

    except Exception as e:
        print(f"\nâŒ Verification error: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)


if __name__ == '__main__':
    main()
