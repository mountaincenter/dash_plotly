name: S3 Reconcile by manifest.json

on:
  workflow_dispatch:
    inputs:
      dry_run:
        description: "Preview only (no changes to S3)"
        type: boolean
        default: true

permissions:
  id-token: write
  contents: read

jobs:
  reconcile:
    runs-on: ubuntu-latest
    environment:
      name: "AWS_OIDC"

    env:
      MANIFEST_PATH: data/parquet/manifest.json
      S3_BUCKET: ${{ vars.DATA_BUCKET || vars.S3_BUCKET }}
      S3_PREFIX: ${{ vars.PARQUET_PREFIX || 'parquet/' }}

    steps:
      - uses: actions/checkout@v4

      - uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: ${{ secrets.AWS_ROLE_ARN }}
          aws-region: ${{ vars.AWS_REGION }}

      - name: Show inputs/vars
        run: |
          echo "dry_run=${{ github.event.inputs.dry_run }}"
          echo "S3_BUCKET=${{ env.S3_BUCKET }}"
          echo "S3_PREFIX=${{ env.S3_PREFIX }}"

      - name: Download current manifest.json from S3
        run: |
          set -euo pipefail
          echo "Downloading manifest.json from S3..."
          aws s3 cp "s3://${{ env.S3_BUCKET }}/${{ env.S3_PREFIX }}manifest.json" "$MANIFEST_PATH" || {
            echo "::warning::manifest.json not found in S3. Reconciliation may not be needed."
            exit 0
          }

      - name: Validate manifest.json
        run: |
          set -euo pipefail
          test -f "$MANIFEST_PATH" || { echo "::error::manifest not found: $MANIFEST_PATH"; exit 1; }
          jq type "$MANIFEST_PATH" >/dev/null
          jq -e '.files and (.files | type=="object")' "$MANIFEST_PATH" >/dev/null

      - name: Report missing objects listed in manifest (informational)
        run: |
          set -euo pipefail
          mapfile -t HAVE < <(aws s3api list-objects-v2 \
            --bucket "${{ env.S3_BUCKET }}" --prefix "${{ env.S3_PREFIX }}" \
            --query 'Contents[].Key' --output text 2>/dev/null | tr '\t' '\n' | sed '/^$/d')

          # Extract filenames from manifest (files object keys)
          mapfile -t WANTED_FILES < <(jq -r '.files | keys[]' "$MANIFEST_PATH")

          # Convert to S3 keys
          missing=()
          for filename in "${WANTED_FILES[@]}"; do
            s3_key="${{ env.S3_PREFIX }}${filename}"
            found=false
            for h in "${HAVE[@]}"; do
              if [ "$h" = "$s3_key" ]; then found=true; break; fi
            done
            if [ "$found" = false ]; then
              # Check if file exists according to manifest
              EXISTS=$(jq -r --arg f "$filename" '.files[$f].exists' "$MANIFEST_PATH")
              if [ "$EXISTS" = "true" ]; then
                missing+=("$s3_key")
              fi
            fi
          done

          if [ ${#missing[@]} -gt 0 ]; then
            echo "::warning::Missing objects on S3 (listed in manifest but not found):"
            printf '  - %s\n' "${missing[@]}"
          else
            echo "✅ All manifest-listed objects exist on S3."
          fi

      - name: Delete objects NOT in manifest (make S3 clean)
        env:
          DRYRUN: ${{ github.event.inputs.dry_run }}
        run: |
          set -euo pipefail
          mapfile -t HAVE < <(aws s3api list-objects-v2 \
            --bucket "${{ env.S3_BUCKET }}" --prefix "${{ env.S3_PREFIX }}" \
            --query 'Contents[].Key' --output text 2>/dev/null | tr '\t' '\n' | sed '/^$/d')

          echo "S3 has (${#HAVE[@]}) objects:"
          printf '  - %s\n' "${HAVE[@]}"

          # Extract filenames from manifest and convert to S3 keys
          mapfile -t WANTED_FILES < <(jq -r '.files | keys[]' "$MANIFEST_PATH")
          WANTED_S3KEYS=()
          for filename in "${WANTED_FILES[@]}"; do
            WANTED_S3KEYS+=("${{ env.S3_PREFIX }}${filename}")
          done

          # Always protect manifest.json
          PROTECT=("${{ env.S3_PREFIX }}manifest.json")

          # Find objects to delete
          to_delete=()
          for key in "${HAVE[@]}"; do
            skip=false
            for w in "${WANTED_S3KEYS[@]}"; do [ "$key" = "$w" ] && { skip=true; break; }; done
            for p in "${PROTECT[@]}";    do [ "$key" = "$p" ] && { skip=true; break; }; done
            $skip || to_delete+=("$key")
          done

          echo ""
          echo "Extra keys to delete (${#to_delete[@]}):"
          printf '  - %s\n' "${to_delete[@]}" || true

          # Delete extra files
          for key in "${to_delete[@]}"; do
            if [ "$DRYRUN" = "true" ]; then
              echo "[dry-run] would delete s3://${{ env.S3_BUCKET }}/${key}"
            else
              echo "DELETE s3://${{ env.S3_BUCKET }}/${key}"
              aws s3 rm "s3://${{ env.S3_BUCKET }}/${key}" --only-show-errors || true
            fi
          done

          if [ "$DRYRUN" = "true" ]; then
            echo ""
            echo "✅ Dry run completed - no changes made to S3"
          elif [ ${#to_delete[@]} -gt 0 ]; then
            echo ""
            echo "✅ Deleted ${#to_delete[@]} extra file(s) from S3"
          else
            echo ""
            echo "✅ No extra files to delete"
          fi

      - name: List objects (after reconcile)
        run: |
          echo "Final S3 state:"
          aws s3 ls "s3://${{ env.S3_BUCKET }}/${{ env.S3_PREFIX }}" --recursive
