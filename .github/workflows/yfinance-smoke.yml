name: YFinance Smoke Test

on:
  push:
    branches:
      - yfinance-smoke
  workflow_dispatch: {}

permissions:
  id-token: write
  contents: read

jobs:
  smoke:
    runs-on: ubuntu-latest
    environment: AWS_OIDC

    steps:
      - uses: actions/checkout@v4

      - uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install pandas pyarrow yfinance

      - name: Run yfinance smoke script (5 tickers)
        run: python scripts/yfinance_smoke.py

      - name: Generate parquet samples via yfinance
        run: python scripts/gen_yfinance_parquet.py

      - uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: ${{ secrets.AWS_ROLE_ARN }}
          aws-region: ${{ vars.AWS_REGION || 'ap-northeast-1' }}

      - name: Upload sample parquet to S3
        env:
          S3_BUCKET: ${{ vars.S3_BUCKET }}
          PARQUET_PREFIX: ${{ vars.PARQUET_PREFIX }}
        run: |
          set -euo pipefail
          if [ -z "${S3_BUCKET:-}" ]; then
            echo "::error::S3_BUCKET (vars.S3_BUCKET) is not defined."
            exit 1
          fi
          PREFIX="${PARQUET_PREFIX:-parquet/}"
          shopt -s nullglob
          files=(yfinance-smoke-test-*.parquet)
          if [ ${#files[@]} -eq 0 ]; then
            echo "::error::No parquet files found to upload."
            exit 1
          fi
          for file in "${files[@]}"; do
            dest_key="${PREFIX%/}/smoke/${file}"
            aws s3 cp \
              "$file" \
              "s3://${S3_BUCKET}/${dest_key}" \
              --sse AES256 \
              --cache-control "max-age=60" \
              --only-show-errors
            echo "uploaded to s3://${S3_BUCKET}/${dest_key}"
          done

      - name: Upload parquet artifact
        uses: actions/upload-artifact@v4
        with:
          name: yfinance-smoke-test
          path: yfinance-smoke-test-*.parquet
