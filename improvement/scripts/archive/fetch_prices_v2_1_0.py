#!/usr/bin/env python3
"""
fetch_prices_v2_1_0.py
grok_analysis_merged_20251121.parquetã®131éŠ˜æŸ„ã«å¯¾ã—ã¦æ—¢å­˜ã®pricesãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ›´æ–°

æ›´æ–°ã™ã‚‹ãƒ•ã‚¡ã‚¤ãƒ«:
- prices_max_1d.parquet (æ—¢å­˜ã‚’131éŠ˜æŸ„ã§ãƒ•ã‚£ãƒ«ã‚¿ + ä¸è¶³éŠ˜æŸ„ã‚’è¿½åŠ å–å¾—)
- prices_60d_5m.parquet (æ—¢å­˜ã‚’131éŠ˜æŸ„ã§ãƒ•ã‚£ãƒ«ã‚¿ + ä¸è¶³éŠ˜æŸ„ã‚’è¿½åŠ å–å¾—)
- prices_max_5m.parquet (æ–°è¦ä½œæˆ)
- prices_60d_1d.parquet (æ–°è¦ä½œæˆ)
"""

from __future__ import annotations

import sys
from pathlib import Path
from typing import List, Set

ROOT = Path(__file__).resolve().parents[2]  # improvement/scripts/ ã‹ã‚‰2éšå±¤ä¸Š
if str(ROOT) not in sys.path:
    sys.path.insert(0, str(ROOT))

import pandas as pd
from scripts.lib.yfinance_fetcher import fetch_prices_for_tickers

# ãƒ‘ã‚¹è¨­å®š
IMPROVEMENT_DATA_DIR = ROOT / "improvement" / "data"
GROK_ANALYSIS_FILE = IMPROVEMENT_DATA_DIR / "grok_analysis_merged_20251121.parquet"

# æ›´æ–°ã™ã‚‹ä¾¡æ ¼ãƒ‡ãƒ¼ã‚¿ã®è¨­å®š
PRICE_CONFIGS = [
    {"period": "max", "interval": "1d", "filename": "prices_max_1d.parquet", "exists": True},
    {"period": "60d", "interval": "5m", "filename": "prices_60d_5m.parquet", "exists": True},
    {"period": "max", "interval": "5m", "filename": "prices_max_5m.parquet", "exists": False},
    {"period": "60d", "interval": "1d", "filename": "prices_60d_1d.parquet", "exists": False},
]


def load_tickers_from_grok_analysis() -> List[str]:
    """grok_analysis_merged_20251121.parquetã‹ã‚‰ãƒ†ã‚£ãƒƒã‚«ãƒ¼ãƒªã‚¹ãƒˆã‚’å–å¾—"""
    if not GROK_ANALYSIS_FILE.exists():
        raise FileNotFoundError(
            f"grok_analysis_merged_20251121.parquet not found: {GROK_ANALYSIS_FILE}"
        )

    print(f"[INFO] Loading grok_analysis_merged_20251121.parquet: {GROK_ANALYSIS_FILE}")
    df = pd.read_parquet(GROK_ANALYSIS_FILE)
    tickers = df["ticker"].unique().tolist()
    print(f"  âœ“ Loaded {len(tickers)} unique tickers")
    return tickers


def update_or_create_prices(
    target_tickers: Set[str], period: str, interval: str, output_path: Path, file_exists: bool
) -> bool:
    """
    æ—¢å­˜ãƒ•ã‚¡ã‚¤ãƒ«ã‚’131éŠ˜æŸ„ã§ãƒ•ã‚£ãƒ«ã‚¿ã€ã¾ãŸã¯æ–°è¦ä½œæˆ

    Args:
        target_tickers: å¯¾è±¡éŠ˜æŸ„ã‚»ãƒƒãƒˆ (131éŠ˜æŸ„)
        period: ãƒ‡ãƒ¼ã‚¿æœŸé–“
        interval: ãƒ‡ãƒ¼ã‚¿é–“éš”
        output_path: ä¿å­˜å…ˆãƒ‘ã‚¹
        file_exists: æ—¢å­˜ãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã™ã‚‹ã‹

    Returns:
        æˆåŠŸæ™‚Trueã€å¤±æ•—æ™‚False
    """
    print(f"[INFO] Processing: period={period}, interval={interval}, exists={file_exists}")

    if file_exists and output_path.exists():
        # æ—¢å­˜ãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿
        print(f"  ğŸ“‚ Loading existing file...")
        existing_df = pd.read_parquet(output_path)
        existing_tickers = set(existing_df["ticker"].unique())

        print(f"  ğŸ“Š Existing: {len(existing_tickers)} tickers, {len(existing_df)} rows")

        # 131éŠ˜æŸ„ã§ãƒ•ã‚£ãƒ«ã‚¿
        filtered_df = existing_df[existing_df["ticker"].isin(target_tickers)].copy()
        filtered_tickers = set(filtered_df["ticker"].unique())

        print(f"  ğŸ” After filter: {len(filtered_tickers)} tickers, {len(filtered_df)} rows")

        # ä¸è¶³éŠ˜æŸ„ã‚’ç‰¹å®š
        missing_tickers = target_tickers - filtered_tickers

        if missing_tickers:
            print(f"  âš  Missing {len(missing_tickers)} tickers, fetching from yfinance...")
            try:
                new_df = fetch_prices_for_tickers(list(missing_tickers), period, interval, None)
                if not new_df.empty:
                    # æ—¢å­˜ãƒ‡ãƒ¼ã‚¿ã¨çµåˆ
                    combined_df = pd.concat([filtered_df, new_df], ignore_index=True)
                    print(f"  âœ“ Fetched {len(new_df)} rows for missing tickers")
                else:
                    combined_df = filtered_df
                    print(f"  âš  No data retrieved for missing tickers")
            except Exception as e:
                print(f"  âœ— Failed to fetch missing tickers: {e}")
                combined_df = filtered_df
        else:
            print(f"  âœ… All 131 tickers present in existing file")
            combined_df = filtered_df

        # ä¿å­˜
        combined_df.to_parquet(output_path, engine="pyarrow", index=False)
        final_tickers = combined_df["ticker"].nunique()
        print(f"  ğŸ’¾ Saved: {output_path} ({final_tickers} tickers, {len(combined_df)} rows)")
        return True

    else:
        # æ–°è¦ä½œæˆ
        print(f"  ğŸ†• Creating new file from yfinance...")
        try:
            df = fetch_prices_for_tickers(list(target_tickers), period, interval, None)

            if df.empty:
                print(f"  âš  No data retrieved")
                df = pd.DataFrame(columns=["date", "Open", "High", "Low", "Close", "Volume", "ticker"])

            # ä¿å­˜
            IMPROVEMENT_DATA_DIR.mkdir(parents=True, exist_ok=True)
            df.to_parquet(output_path, engine="pyarrow", index=False)
            print(f"  ğŸ’¾ Saved: {output_path} ({df['ticker'].nunique()} tickers, {len(df)} rows)")
            return True

        except Exception as e:
            print(f"  âœ— Failed: {e}")
            # ã‚¨ãƒ©ãƒ¼æ™‚ã¯ç©ºãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆ
            empty_df = pd.DataFrame(columns=["date", "Open", "High", "Low", "Close", "Volume", "ticker"])
            empty_df.to_parquet(output_path, engine="pyarrow", index=False)
            print(f"  âš  Created empty file due to error")
            return False


def main() -> int:
    print("=" * 60)
    print("Update Price Files for v2.1.0 Analysis (131 tickers)")
    print("=" * 60)

    # [STEP 1] ãƒ†ã‚£ãƒƒã‚«ãƒ¼ãƒªã‚¹ãƒˆå–å¾—
    print("\n[STEP 1] Loading tickers from grok_analysis_merged_20251121.parquet...")
    try:
        tickers = load_tickers_from_grok_analysis()
        target_tickers = set(tickers)
        print(f"  âœ“ {len(target_tickers)} unique tickers")
    except Exception as e:
        print(f"  âœ— Failed: {e}")
        return 1

    # [STEP 2] ä¾¡æ ¼ãƒ‡ãƒ¼ã‚¿æ›´æ–°/ä½œæˆï¼ˆ4ãƒ‘ã‚¿ãƒ¼ãƒ³ï¼‰
    print("\n[STEP 2] Updating/creating price files...")
    success_count = 0

    for i, config in enumerate(PRICE_CONFIGS, 1):
        print(f"\n  [{i}/{len(PRICE_CONFIGS)}] {config['filename']}")
        output_path = IMPROVEMENT_DATA_DIR / config["filename"]

        if update_or_create_prices(
            target_tickers, config["period"], config["interval"], output_path, config["exists"]
        ):
            success_count += 1

    # ã‚µãƒãƒªãƒ¼
    print("\n" + "=" * 60)
    print("Summary")
    print("=" * 60)
    print(f"Target tickers: {len(target_tickers)}")
    print(f"Price datasets: {success_count}/{len(PRICE_CONFIGS)} successful")
    print("=" * 60)

    if success_count == len(PRICE_CONFIGS):
        print("\nâœ… All price files updated successfully!")
        return 0
    else:
        print(f"\nâš  Only {success_count}/{len(PRICE_CONFIGS)} datasets updated")
        return 1


if __name__ == "__main__":
    raise SystemExit(main())
